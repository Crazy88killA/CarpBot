
import spacy
import re
import markovify
import nltk
import warnings
warnings.filterwarnings('ignore')
nltk.download()



nltk.data.find(r'C:\Users\User\OneDrive\Desktop\CarpBot')

open(r"Carpentaria.txt", 'r')
print(content_of_file)


#import novels as text objects

open('Carpentaria.txt','r')
textfile.read(Carpentaria.txt)
open (Carpentaria.txt,r)
for line in f:
  print(line.strip())



#print first 100 characters of each
print('\ntxt:\n', Carpentaria[:100])



#utility function for text cleaning
def text_cleaner(text):
  text = re.sub(r'--', ' ', text)
text = re.sub('[\[].*?[\]]', '', text)
text = re.sub(r'(\b|\s+\-?|^\-?)(\d+|\d*\.\d+)\b','', text)
text = ' '.join(text.split())



#apply cleaning function to corpus
Carpentaria = text_cleaner(Carpentaria)


#parse cleaned novels
nlp = spacy.load('en')
Carpentaria_doc = nlp(Carpentaria)

Carpentaria_sents = ' '.join([sent.text for sent in Carpentaria_doc.sents if len(sent.text) > 1])

#inspect our text
print(Carpentaria_sents)

#create text generator using markovify
generator_1 = markovify.Text(shakespeare_sents, state_size=3)

#We will randomly generate three sentences
for i in range(3):
  print(generator_1.make_sentence())
#We will randomly generate three more sentences of no more than 100 characters
for i in range(3):
  print(generator_1.make_short_sentence(max_chars=100))

#now we will use the above generator to generate sentences
for i in range(5):
  print(generator_2.make_sentence())
#print 100 characters or less sentences
for i in range(5):
  print(generator_2.make_short_sentence(max_chars=100))